{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7124276",
   "metadata": {},
   "source": [
    "# Base example: How to Langchain\n",
    "This is a simple example of how to use Langchain to split python files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab0830c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, PythonLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_ollama import OllamaLLM\n",
    "# from langchain_community.llms import CTransformers\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.text_splitter import NLTKTextSplitter\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34f384c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DirectoryLoader(\"../capstone/S35-Capstone-Backend\",\n",
    "                         glob=\"*.py\", loader_cls=PythonLoader, recursive=True)\n",
    "# interpret information in the documents\n",
    "documents = loader.load()\n",
    "\n",
    "for i, v in enumerate(documents):\n",
    "    print(i, v)\n",
    "# splitter = RecursiveCharacterTextSplitter(chunk_size=256,\n",
    "#                                           chunk_overlap=20)\n",
    "# texts = splitter.split_documents(documents)\n",
    "\n",
    "# text_splitter = NLTKTextSplitter()\n",
    "# texts = text_splitter.split_documents(documents)\n",
    "\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    model_kwargs={'device': \"cuda\"})\n",
    "\n",
    "# create and save the local database\n",
    "db = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "template = \"\"\"Use the following context to answer the user's question. \n",
    "Context: {context}\n",
    "Question: {input}\n",
    "\"\"\"\n",
    "\n",
    "# load the language model\n",
    "llm = OllamaLLM(model=\"llama3.1:8b\",\n",
    "                num_predict=-1,\n",
    "                temperature=0.1)\n",
    "# llm = CTransformers(model='./llama-2-7b-chat.ggmlv3.q8_0.bin',\n",
    "#                     model_type='llama',\n",
    "#                     gpu_layers=50,\n",
    "#                     config={'max_new_tokens': 1024, 'temperature': 0.05})\n",
    "\n",
    "\n",
    "# prepare a version of the llm pre-loaded with the local content\n",
    "retriever = db.as_retriever(search_kwargs={'k': 5})\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=['context', 'input'])\n",
    "\n",
    "combine_docs_chain = create_stuff_documents_chain(llm, prompt)\n",
    "qa_llm = create_retrieval_chain(retriever, combine_docs_chain)\n",
    "\n",
    "# qa_llm = RetrievalQA.from_chain_type(llm=llm,\n",
    "#                                      chain_type='stuff',\n",
    "#                                      retriever=retriever,\n",
    "#                                      return_source_documents=True,\n",
    "#                                      chain_type_kwargs={'prompt': prompt})\n",
    "\n",
    "# ask the AI chat about information in our local files\n",
    "\n",
    "while True:\n",
    "    inputP = input(\"What do you want to ask?\\n\")\n",
    "    output = qa_llm.invoke({\"input\": inputP})\n",
    "    print(output[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b36d1d2",
   "metadata": {},
   "source": [
    "# Modified example: Custom Retriever\n",
    "\n",
    "Testing if using a custom AST based retriever to split makes it better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb8c6880",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(os.path.abspath('')), '../ast_tokenizer/languages/python_ast')))\n",
    "from python_ast import PythonASTDocumentLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cb9426b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DirectoryLoader(\"../\",\n",
    "                         glob=\"*.py\", loader_cls=PythonASTDocumentLoader, recursive=True)\n",
    "# interpret information in the documents\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da8be853-c696-4662-9100-6b0005c4c426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 page_content='from langchain_text_splitters import (\n",
      "    Language,\n",
      "    RecursiveCharacterTextSplitter,\n",
      ")' metadata={'relative_path': '../testing/test_splitter.py', 'start_offset': 0, 'end_offset': 90, 'block_type': 'others', 'block_name': 'Block at 0-90', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': [], 'docstrings': [], 'comments': []}\n",
      "1 page_content='from langchain_community.document_loaders import DirectoryLoader, PythonLoader' metadata={'relative_path': '../testing/test_splitter.py', 'start_offset': 91, 'end_offset': 169, 'block_type': 'others', 'block_name': 'Block at 91-169', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': [], 'docstrings': [], 'comments': []}\n",
      "2 page_content='from langchain_community.document_loaders.parsers.language.python import PythonSegmenter' metadata={'relative_path': '../testing/test_splitter.py', 'start_offset': 170, 'end_offset': 258, 'block_type': 'others', 'block_name': 'Block at 170-258', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': [], 'docstrings': [], 'comments': []}\n",
      "3 page_content='with open(\"../../frontend/ui/ui.py\") as f:\n",
      "    PYTHON_CODE = f.read()' metadata={'relative_path': '../testing/test_splitter.py', 'start_offset': 260, 'end_offset': 329, 'block_type': 'others', 'block_name': 'Block at 260-329', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': ['open(\"../../frontend/ui/ui.py\")', 'f.read()'], 'docstrings': [], 'comments': []}\n",
      "4 page_content='python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
      "    language=Language.PYTHON, chunk_size=50, chunk_overlap=0\n",
      ")' metadata={'relative_path': '../testing/test_splitter.py', 'start_offset': 331, 'end_offset': 457, 'block_type': 'others', 'block_name': 'Block at 331-457', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': ['RecursiveCharacterTextSplitter.from_language(\\n    language=Language.PYTHON, chunk_size=50, chunk_overlap=0\\n)'], 'docstrings': [], 'comments': []}\n",
      "5 page_content='python_docs = python_splitter.create_documents([PYTHON_CODE])' metadata={'relative_path': '../testing/test_splitter.py', 'start_offset': 458, 'end_offset': 519, 'block_type': 'others', 'block_name': 'Block at 458-519', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': ['python_splitter.create_documents([PYTHON_CODE])'], 'docstrings': [], 'comments': []}\n",
      "6 page_content='# for doc in python_docs:' metadata={'relative_path': '../testing/test_splitter.py', 'start_offset': 521, 'end_offset': 546, 'block_type': 'others', 'block_name': 'Block at 521-546', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': [], 'docstrings': [], 'comments': ['for doc in python_docs:']}\n",
      "7 page_content='# Splitter splits per line or statement naively' metadata={'relative_path': '../testing/test_splitter.py', 'start_offset': 551, 'end_offset': 598, 'block_type': 'others', 'block_name': 'Block at 551-598', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': [], 'docstrings': [], 'comments': ['Splitter splits per line or statement naively']}\n",
      "8 page_content='# print(type(doc), doc)' metadata={'relative_path': '../testing/test_splitter.py', 'start_offset': 603, 'end_offset': 626, 'block_type': 'others', 'block_name': 'Block at 603-626', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': [], 'docstrings': [], 'comments': ['print(type(doc), doc)']}\n",
      "9 page_content='print(\"\\n\\n\\n\")' metadata={'relative_path': '../testing/test_splitter.py', 'start_offset': 629, 'end_offset': 644, 'block_type': 'others', 'block_name': 'Block at 629-644', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': ['print(\"\\\\n\\\\n\\\\n\")'], 'docstrings': [], 'comments': []}\n",
      "10 page_content='print(\"TESTINGTESTINGTESTING\")' metadata={'relative_path': '../testing/test_splitter.py', 'start_offset': 645, 'end_offset': 675, 'block_type': 'others', 'block_name': 'Block at 645-675', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': ['print(\"TESTINGTESTINGTESTING\")'], 'docstrings': [], 'comments': []}\n",
      "11 page_content='print(\"\\n\\n\\n\")' metadata={'relative_path': '../testing/test_splitter.py', 'start_offset': 676, 'end_offset': 691, 'block_type': 'others', 'block_name': 'Block at 676-691', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': ['print(\"\\\\n\\\\n\\\\n\")'], 'docstrings': [], 'comments': []}\n",
      "12 page_content='loader = PythonLoader(\"mainFile.py\")' metadata={'relative_path': '../testing/test_splitter.py', 'start_offset': 693, 'end_offset': 729, 'block_type': 'others', 'block_name': 'Block at 693-729', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': ['PythonLoader(\"mainFile.py\")'], 'docstrings': [], 'comments': []}\n",
      "13 page_content='loader_docs = loader.load()' metadata={'relative_path': '../testing/test_splitter.py', 'start_offset': 730, 'end_offset': 757, 'block_type': 'others', 'block_name': 'Block at 730-757', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': ['loader.load()'], 'docstrings': [], 'comments': []}\n",
      "14 page_content='# for doc in loader_docs:' metadata={'relative_path': '../testing/test_splitter.py', 'start_offset': 759, 'end_offset': 784, 'block_type': 'others', 'block_name': 'Block at 759-784', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': [], 'docstrings': [], 'comments': ['for doc in loader_docs:']}\n",
      "15 page_content='# PythonLoader has a large chunk size, but can load from files directly' metadata={'relative_path': '../testing/test_splitter.py', 'start_offset': 789, 'end_offset': 860, 'block_type': 'others', 'block_name': 'Block at 789-860', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': [], 'docstrings': [], 'comments': ['PythonLoader has a large chunk size, but can load from files directly']}\n",
      "16 page_content='# Results in one huge document, that needs further recursive splitting' metadata={'relative_path': '../testing/test_splitter.py', 'start_offset': 865, 'end_offset': 935, 'block_type': 'others', 'block_name': 'Block at 865-935', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': [], 'docstrings': [], 'comments': ['Results in one huge document, that needs further recursive splitting']}\n",
      "17 page_content='# print(type(doc), doc)' metadata={'relative_path': '../testing/test_splitter.py', 'start_offset': 940, 'end_offset': 963, 'block_type': 'others', 'block_name': 'Block at 940-963', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': [], 'docstrings': [], 'comments': ['print(type(doc), doc)']}\n",
      "18 page_content='segmenter = PythonSegmenter(PYTHON_CODE)' metadata={'relative_path': '../testing/test_splitter.py', 'start_offset': 965, 'end_offset': 1005, 'block_type': 'others', 'block_name': 'Block at 965-1005', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': ['PythonSegmenter(PYTHON_CODE)'], 'docstrings': [], 'comments': []}\n",
      "19 page_content='print(segmenter.is_valid())' metadata={'relative_path': '../testing/test_splitter.py', 'start_offset': 1006, 'end_offset': 1033, 'block_type': 'others', 'block_name': 'Block at 1006-1033', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': ['print(segmenter.is_valid())', 'segmenter.is_valid()'], 'docstrings': [], 'comments': []}\n",
      "20 page_content='print(\"\\n Class Func\\n\")' metadata={'relative_path': '../testing/test_splitter.py', 'start_offset': 1034, 'end_offset': 1058, 'block_type': 'others', 'block_name': 'Block at 1034-1058', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': ['print(\"\\\\n Class Func\\\\n\")'], 'docstrings': [], 'comments': []}\n",
      "21 page_content='print(segmenter.extract_functions_classes())' metadata={'relative_path': '../testing/test_splitter.py', 'start_offset': 1059, 'end_offset': 1103, 'block_type': 'others', 'block_name': 'Block at 1059-1103', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': ['print(segmenter.extract_functions_classes())', 'segmenter.extract_functions_classes()'], 'docstrings': [], 'comments': []}\n",
      "22 page_content='print(\"\\n Simplified \\n\")' metadata={'relative_path': '../testing/test_splitter.py', 'start_offset': 1104, 'end_offset': 1129, 'block_type': 'others', 'block_name': 'Block at 1104-1129', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': ['print(\"\\\\n Simplified \\\\n\")'], 'docstrings': [], 'comments': []}\n",
      "23 page_content='print(segmenter.simplify_code())' metadata={'relative_path': '../testing/test_splitter.py', 'start_offset': 1130, 'end_offset': 1162, 'block_type': 'others', 'block_name': 'Block at 1130-1162', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': ['print(segmenter.simplify_code())', 'segmenter.simplify_code()'], 'docstrings': [], 'comments': []}\n",
      "24 page_content='from langchain_text_splitters import (\n",
      "    Language,\n",
      "    RecursiveCharacterTextSplitter,\n",
      ")\n",
      "from langchain_community.document_loaders import DirectoryLoader, PythonLoader\n",
      "from langchain_community.document_loaders.parsers.language.python import PythonSegmenter\n",
      "with open(\"../../frontend/ui/ui.py\") as f:\n",
      "    PYTHON_CODE = f.read()\n",
      "python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
      "    language=Language.PYTHON, chunk_size=50, chunk_overlap=0\n",
      ")\n",
      "python_docs = python_splitter.create_documents([PYTHON_CODE])\n",
      "# for doc in python_docs:\n",
      "# Splitter splits per line or statement naively\n",
      "# print(type(doc), doc)\n",
      "print(\"\\n\\n\\n\")\n",
      "print(\"TESTINGTESTINGTESTING\")\n",
      "print(\"\\n\\n\\n\")\n",
      "loader = PythonLoader(\"mainFile.py\")\n",
      "loader_docs = loader.load()\n",
      "# for doc in loader_docs:\n",
      "# PythonLoader has a large chunk size, but can load from files directly\n",
      "# Results in one huge document, that needs further recursive splitting\n",
      "# print(type(doc), doc)\n",
      "segmenter = PythonSegmenter(PYTHON_CODE)\n",
      "print(segmenter.is_valid())\n",
      "print(\"\\n Class Func\\n\")\n",
      "print(segmenter.extract_functions_classes())\n",
      "print(\"\\n Simplified \\n\")\n",
      "print(segmenter.simplify_code())\n",
      "' metadata={'relative_path': '../testing/test_splitter.py', 'start_offset': 0, 'end_offset': 1162, 'block_type': 'others', 'block_name': 'Combined Others', 'block_args': [], 'parent_type': 'root', 'parent_name': 'root', 'functions_called': ['open(\"../../frontend/ui/ui.py\")', 'f.read()', 'RecursiveCharacterTextSplitter.from_language(\\n    language=Language.PYTHON, chunk_size=50, chunk_overlap=0\\n)', 'python_splitter.create_documents([PYTHON_CODE])', 'print(\"\\\\n\\\\n\\\\n\")', 'print(\"TESTINGTESTINGTESTING\")', 'print(\"\\\\n\\\\n\\\\n\")', 'PythonLoader(\"mainFile.py\")', 'loader.load()', 'PythonSegmenter(PYTHON_CODE)', 'print(segmenter.is_valid())', 'segmenter.is_valid()', 'print(\"\\\\n Class Func\\\\n\")', 'print(segmenter.extract_functions_classes())', 'segmenter.extract_functions_classes()', 'print(\"\\\\n Simplified \\\\n\")', 'print(segmenter.simplify_code())', 'segmenter.simplify_code()'], 'docstrings': [], 'comments': ['for doc in python_docs:', 'Splitter splits per line or statement naively', 'print(type(doc), doc)', 'for doc in loader_docs:', 'PythonLoader has a large chunk size, but can load from files directly', 'Results in one huge document, that needs further recursive splitting', 'print(type(doc), doc)']}\n",
      "25 page_content='from langchain_community.document_loaders import DirectoryLoader, TextLoader, PythonLoader' metadata={'relative_path': '../testing/mainFile.py', 'start_offset': 0, 'end_offset': 90, 'block_type': 'others', 'block_name': 'Block at 0-90', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': [], 'docstrings': [], 'comments': []}\n",
      "26 page_content='from langchain.text_splitter import RecursiveCharacterTextSplitter' metadata={'relative_path': '../testing/mainFile.py', 'start_offset': 92, 'end_offset': 158, 'block_type': 'others', 'block_name': 'Block at 92-158', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': [], 'docstrings': [], 'comments': []}\n",
      "27 page_content='from langchain_huggingface import HuggingFaceEmbeddings' metadata={'relative_path': '../testing/mainFile.py', 'start_offset': 160, 'end_offset': 215, 'block_type': 'others', 'block_name': 'Block at 160-215', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': [], 'docstrings': [], 'comments': []}\n",
      "28 page_content='from langchain_community.vectorstores import FAISS' metadata={'relative_path': '../testing/mainFile.py', 'start_offset': 217, 'end_offset': 267, 'block_type': 'others', 'block_name': 'Block at 217-267', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': [], 'docstrings': [], 'comments': []}\n",
      "29 page_content='from langchain_ollama import OllamaLLM' metadata={'relative_path': '../testing/mainFile.py', 'start_offset': 269, 'end_offset': 307, 'block_type': 'others', 'block_name': 'Block at 269-307', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': [], 'docstrings': [], 'comments': []}\n",
      "' metadata={'relative_path': '../testing/mainFile.py', 'start_offset': 309, 'end_offset': 362, 'block_type': 'others', 'block_name': 'Block at 309-362', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': [], 'docstrings': [], 'comments': ['from langchain_community.llms import CTransformers']}\n",
      "31 page_content='from langchain_core.prompts import PromptTemplate' metadata={'relative_path': '../testing/mainFile.py', 'start_offset': 363, 'end_offset': 412, 'block_type': 'others', 'block_name': 'Block at 363-412', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': [], 'docstrings': [], 'comments': []}\n",
      "32 page_content='from langchain.chains import RetrievalQA' metadata={'relative_path': '../testing/mainFile.py', 'start_offset': 414, 'end_offset': 454, 'block_type': 'others', 'block_name': 'Block at 414-454', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': [], 'docstrings': [], 'comments': []}\n",
      "33 page_content='from langchain.chains import create_retrieval_chain' metadata={'relative_path': '../testing/mainFile.py', 'start_offset': 456, 'end_offset': 507, 'block_type': 'others', 'block_name': 'Block at 456-507', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': [], 'docstrings': [], 'comments': []}\n",
      "34 page_content='from langchain.chains.combine_documents import create_stuff_documents_chain' metadata={'relative_path': '../testing/mainFile.py', 'start_offset': 509, 'end_offset': 584, 'block_type': 'others', 'block_name': 'Block at 509-584', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': [], 'docstrings': [], 'comments': []}\n",
      "35 page_content='from langchain.text_splitter import NLTKTextSplitter' metadata={'relative_path': '../testing/mainFile.py', 'start_offset': 586, 'end_offset': 638, 'block_type': 'others', 'block_name': 'Block at 586-638', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': [], 'docstrings': [], 'comments': []}\n",
      "36 page_content='import torch' metadata={'relative_path': '../testing/mainFile.py', 'start_offset': 640, 'end_offset': 652, 'block_type': 'others', 'block_name': 'Block at 640-652', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': [], 'docstrings': [], 'comments': []}\n",
      "37 page_content='loader = DirectoryLoader(\"../capstone/S35-Capstone-Backend\",\n",
      "                         glob=\"*.py\", loader_cls=PythonLoader, recursive=True)' metadata={'relative_path': '../testing/mainFile.py', 'start_offset': 658, 'end_offset': 798, 'block_type': 'others', 'block_name': 'Block at 658-798', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': ['DirectoryLoader(\"../capstone/S35-Capstone-Backend\",\\r\\n                         glob=\"*.py\", loader_cls=PythonLoader, recursive=True)'], 'docstrings': [], 'comments': []}\n",
      "' metadata={'relative_path': '../testing/mainFile.py', 'start_offset': 800, 'end_offset': 841, 'block_type': 'others', 'block_name': 'Block at 800-841', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': [], 'docstrings': [], 'comments': ['interpret information in the documents']}\n",
      "39 page_content='documents = loader.load()' metadata={'relative_path': '../testing/mainFile.py', 'start_offset': 842, 'end_offset': 867, 'block_type': 'others', 'block_name': 'Block at 842-867', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': ['loader.load()'], 'docstrings': [], 'comments': []}\n",
      "40 page_content='for i, v in enumerate(documents):\n",
      "    print(i, v)' metadata={'relative_path': '../testing/mainFile.py', 'start_offset': 871, 'end_offset': 921, 'block_type': 'others', 'block_name': 'Block at 871-921', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': ['enumerate(documents)', 'print(i, v)'], 'docstrings': [], 'comments': []}\n",
      "' metadata={'relative_path': '../testing/mainFile.py', 'start_offset': 923, 'end_offset': 983, 'block_type': 'others', 'block_name': 'Block at 923-983', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': [], 'docstrings': [], 'comments': ['splitter = RecursiveCharacterTextSplitter(chunk_size=256,']}\n",
      "' metadata={'relative_path': '../testing/mainFile.py', 'start_offset': 984, 'end_offset': 1046, 'block_type': 'others', 'block_name': 'Block at 984-1046', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': [], 'docstrings': [], 'comments': ['chunk_overlap=20)']}\n",
      "' metadata={'relative_path': '../testing/mainFile.py', 'start_offset': 1047, 'end_offset': 1093, 'block_type': 'others', 'block_name': 'Block at 1047-1093', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': [], 'docstrings': [], 'comments': ['texts = splitter.split_documents(documents)']}\n",
      "' metadata={'relative_path': '../testing/mainFile.py', 'start_offset': 1096, 'end_offset': 1133, 'block_type': 'others', 'block_name': 'Block at 1096-1133', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': [], 'docstrings': [], 'comments': ['text_splitter = NLTKTextSplitter()']}\n",
      "' metadata={'relative_path': '../testing/mainFile.py', 'start_offset': 1134, 'end_offset': 1185, 'block_type': 'others', 'block_name': 'Block at 1134-1185', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': [], 'docstrings': [], 'comments': ['texts = text_splitter.split_documents(documents)']}\n",
      "46 page_content='embeddings = HuggingFaceEmbeddings(\n",
      "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
      "    model_kwargs={'device': \"cuda\"})' metadata={'relative_path': '../testing/mainFile.py', 'start_offset': 1190, 'end_offset': 1321, 'block_type': 'others', 'block_name': 'Block at 1190-1321', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': ['HuggingFaceEmbeddings(\\r\\n    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\\r\\n    model_kwargs={\\'device\\': \"cuda\"})'], 'docstrings': [], 'comments': []}\n",
      "' metadata={'relative_path': '../testing/mainFile.py', 'start_offset': 1325, 'end_offset': 1362, 'block_type': 'others', 'block_name': 'Block at 1325-1362', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': [], 'docstrings': [], 'comments': ['create and save the local database']}\n",
      "48 page_content='db = FAISS.from_documents(documents, embeddings)' metadata={'relative_path': '../testing/mainFile.py', 'start_offset': 1363, 'end_offset': 1411, 'block_type': 'others', 'block_name': 'Block at 1363-1411', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': ['FAISS.from_documents(documents, embeddings)'], 'docstrings': [], 'comments': []}\n",
      "49 page_content='template = \"\"\"Use the following context to answer the user's question. \n",
      "Context: {context}\n",
      "Question: {input}\n",
      "\"\"\"' metadata={'relative_path': '../testing/mainFile.py', 'start_offset': 1415, 'end_offset': 1530, 'block_type': 'others', 'block_name': 'Block at 1415-1530', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': [], 'docstrings': [], 'comments': []}\n",
      "' metadata={'relative_path': '../testing/mainFile.py', 'start_offset': 1534, 'end_offset': 1560, 'block_type': 'others', 'block_name': 'Block at 1534-1560', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': [], 'docstrings': [], 'comments': ['load the language model']}\n",
      "51 page_content='llm = OllamaLLM(model=\"llama3.1:8b\",\n",
      "                num_predict=-1,\n",
      "                temperature=0.1)' metadata={'relative_path': '../testing/mainFile.py', 'start_offset': 1561, 'end_offset': 1664, 'block_type': 'others', 'block_name': 'Block at 1561-1664', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': ['OllamaLLM(model=\"llama3.1:8b\",\\r\\n                num_predict=-1,\\r\\n                temperature=0.1)'], 'docstrings': [], 'comments': []}\n",
      "' metadata={'relative_path': '../testing/mainFile.py', 'start_offset': 1666, 'end_offset': 1731, 'block_type': 'others', 'block_name': 'Block at 1666-1731', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': [], 'docstrings': [], 'comments': [\"llm = CTransformers(model='./llama-2-7b-chat.ggmlv3.q8_0.bin',\"]}\n",
      "' metadata={'relative_path': '../testing/mainFile.py', 'start_offset': 1732, 'end_offset': 1774, 'block_type': 'others', 'block_name': 'Block at 1732-1774', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': [], 'docstrings': [], 'comments': [\"model_type='llama',\"]}\n",
      "' metadata={'relative_path': '../testing/mainFile.py', 'start_offset': 1775, 'end_offset': 1812, 'block_type': 'others', 'block_name': 'Block at 1775-1812', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': [], 'docstrings': [], 'comments': ['gpu_layers=50,']}\n",
      "' metadata={'relative_path': '../testing/mainFile.py', 'start_offset': 1813, 'end_offset': 1889, 'block_type': 'others', 'block_name': 'Block at 1813-1889', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': [], 'docstrings': [], 'comments': [\"config={'max_new_tokens': 1024, 'temperature': 0.05})\"]}\n",
      "' metadata={'relative_path': '../testing/mainFile.py', 'start_offset': 1894, 'end_offset': 1959, 'block_type': 'others', 'block_name': 'Block at 1894-1959', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': [], 'docstrings': [], 'comments': ['prepare a version of the llm pre-loaded with the local content']}\n",
      "57 page_content='retriever = db.as_retriever(search_kwargs={'k': 5})' metadata={'relative_path': '../testing/mainFile.py', 'start_offset': 1960, 'end_offset': 2011, 'block_type': 'others', 'block_name': 'Block at 1960-2011', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': [\"db.as_retriever(search_kwargs={'k': 5})\"], 'docstrings': [], 'comments': []}\n",
      "58 page_content='prompt = PromptTemplate(\n",
      "    template=template,\n",
      "    input_variables=['context', 'input'])' metadata={'relative_path': '../testing/mainFile.py', 'start_offset': 2013, 'end_offset': 2104, 'block_type': 'others', 'block_name': 'Block at 2013-2104', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': [\"PromptTemplate(\\r\\n    template=template,\\r\\n    input_variables=['context', 'input'])\"], 'docstrings': [], 'comments': []}\n",
      "59 page_content='combine_docs_chain = create_stuff_documents_chain(llm, prompt)' metadata={'relative_path': '../testing/mainFile.py', 'start_offset': 2108, 'end_offset': 2170, 'block_type': 'others', 'block_name': 'Block at 2108-2170', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': ['create_stuff_documents_chain(llm, prompt)'], 'docstrings': [], 'comments': []}\n",
      "60 page_content='qa_llm = create_retrieval_chain(retriever, combine_docs_chain)' metadata={'relative_path': '../testing/mainFile.py', 'start_offset': 2172, 'end_offset': 2234, 'block_type': 'others', 'block_name': 'Block at 2172-2234', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': ['create_retrieval_chain(retriever, combine_docs_chain)'], 'docstrings': [], 'comments': []}\n",
      "' metadata={'relative_path': '../testing/mainFile.py', 'start_offset': 2238, 'end_offset': 2286, 'block_type': 'others', 'block_name': 'Block at 2238-2286', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': [], 'docstrings': [], 'comments': ['qa_llm = RetrievalQA.from_chain_type(llm=llm,']}\n",
      "' metadata={'relative_path': '../testing/mainFile.py', 'start_offset': 2287, 'end_offset': 2346, 'block_type': 'others', 'block_name': 'Block at 2287-2346', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': [], 'docstrings': [], 'comments': [\"chain_type='stuff',\"]}\n",
      "' metadata={'relative_path': '../testing/mainFile.py', 'start_offset': 2347, 'end_offset': 2407, 'block_type': 'others', 'block_name': 'Block at 2347-2407', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': [], 'docstrings': [], 'comments': ['retriever=retriever,']}\n",
      "' metadata={'relative_path': '../testing/mainFile.py', 'start_offset': 2408, 'end_offset': 2477, 'block_type': 'others', 'block_name': 'Block at 2408-2477', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': [], 'docstrings': [], 'comments': ['return_source_documents=True,']}\n",
      "' metadata={'relative_path': '../testing/mainFile.py', 'start_offset': 2478, 'end_offset': 2555, 'block_type': 'others', 'block_name': 'Block at 2478-2555', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': [], 'docstrings': [], 'comments': [\"chain_type_kwargs={'prompt': prompt})\"]}\n",
      "' metadata={'relative_path': '../testing/mainFile.py', 'start_offset': 2558, 'end_offset': 2613, 'block_type': 'others', 'block_name': 'Block at 2558-2613', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': [], 'docstrings': [], 'comments': ['ask the AI chat about information in our local files']}\n",
      "67 page_content='while True:\n",
      "    inputP = input(\"What do you want to ask?\\n\")\n",
      "    output = qa_llm.invoke({\"input\": inputP})\n",
      "    print(output[\"answer\"])' metadata={'relative_path': '../testing/mainFile.py', 'start_offset': 2616, 'end_offset': 2753, 'block_type': 'others', 'block_name': 'Block at 2616-2753', 'block_args': [], 'parent_type': 'root', 'parent_name': '', 'functions_called': ['input(\"What do you want to ask?\\\\n\")', 'print(output[\"answer\"])', 'qa_llm.invoke({\"input\": inputP})'], 'docstrings': [], 'comments': []}\n",
      "68 page_content='from langchain_community.document_loaders import DirectoryLoader, TextLoader, PythonLoader\n",
      "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
      "from langchain_huggingface import HuggingFaceEmbeddings\n",
      "from langchain_community.vectorstores import FAISS\n",
      "from langchain_ollama import OllamaLLM\n",
      "# from langchain_community.llms import CTransformers\n",
      "from langchain_core.prompts import PromptTemplate\n",
      "from langchain.chains import RetrievalQA\n",
      "from langchain.chains import create_retrieval_chain\n",
      "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
      "from langchain.text_splitter import NLTKTextSplitter\n",
      "import torch\n",
      "loader = DirectoryLoader(\"../capstone/S35-Capstone-Backend\",\n",
      "                         glob=\"*.py\", loader_cls=PythonLoader, recursive=True)\n",
      "# interpret information in the documents\n",
      "documents = loader.load()\n",
      "for i, v in enumerate(documents):\n",
      "    print(i, v)\n",
      "# splitter = RecursiveCharacterTextSplitter(chunk_size=256,\n",
      "#                                           chunk_overlap=20)\n",
      "# texts = splitter.split_documents(documents)\n",
      "# text_splitter = NLTKTextSplitter()\n",
      "# texts = text_splitter.split_documents(documents)\n",
      "embeddings = HuggingFaceEmbeddings(\n",
      "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
      "    model_kwargs={'device': \"cuda\"})\n",
      "# create and save the local database\n",
      "db = FAISS.from_documents(documents, embeddings)\n",
      "template = \"\"\"Use the following context to answer the user's question. \n",
      "Context: {context}\n",
      "Question: {input}\n",
      "\"\"\"\n",
      "# load the language model\n",
      "llm = OllamaLLM(model=\"llama3.1:8b\",\n",
      "                num_predict=-1,\n",
      "                temperature=0.1)\n",
      "# llm = CTransformers(model='./llama-2-7b-chat.ggmlv3.q8_0.bin',\n",
      "#                     model_type='llama',\n",
      "#                     gpu_layers=50,\n",
      "#                     config={'max_new_tokens': 1024, 'temperature': 0.05})\n",
      "# prepare a version of the llm pre-loaded with the local content\n",
      "retriever = db.as_retriever(search_kwargs={'k': 5})\n",
      "prompt = PromptTemplate(\n",
      "    template=template,\n",
      "    input_variables=['context', 'input'])\n",
      "combine_docs_chain = create_stuff_documents_chain(llm, prompt)\n",
      "qa_llm = create_retrieval_chain(retriever, combine_docs_chain)\n",
      "# qa_llm = RetrievalQA.from_chain_type(llm=llm,\n",
      "#                                      chain_type='stuff',\n",
      "#                                      retriever=retriever,\n",
      "#                                      return_source_documents=True,\n",
      "#                                      chain_type_kwargs={'prompt': prompt})\n",
      "# ask the AI chat about information in our local files\n",
      "while True:\n",
      "    inputP = input(\"What do you want to ask?\\n\")\n",
      "    output = qa_llm.invoke({\"input\": inputP})\n",
      "    print(output[\"answer\"])\n",
      "' metadata={'relative_path': '../testing/mainFile.py', 'start_offset': 0, 'end_offset': 2753, 'block_type': 'others', 'block_name': 'Combined Others', 'block_args': [], 'parent_type': 'root', 'parent_name': 'root', 'functions_called': ['DirectoryLoader(\"../capstone/S35-Capstone-Backend\",\\r\\n                         glob=\"*.py\", loader_cls=PythonLoader, recursive=True)', 'loader.load()', 'enumerate(documents)', 'print(i, v)', 'HuggingFaceEmbeddings(\\r\\n    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\\r\\n    model_kwargs={\\'device\\': \"cuda\"})', 'FAISS.from_documents(documents, embeddings)', 'OllamaLLM(model=\"llama3.1:8b\",\\r\\n                num_predict=-1,\\r\\n                temperature=0.1)', \"db.as_retriever(search_kwargs={'k': 5})\", \"PromptTemplate(\\r\\n    template=template,\\r\\n    input_variables=['context', 'input'])\", 'create_stuff_documents_chain(llm, prompt)', 'create_retrieval_chain(retriever, combine_docs_chain)', 'input(\"What do you want to ask?\\\\n\")', 'print(output[\"answer\"])', 'qa_llm.invoke({\"input\": inputP})'], 'docstrings': [], 'comments': ['from langchain_community.llms import CTransformers', 'interpret information in the documents', 'splitter = RecursiveCharacterTextSplitter(chunk_size=256,', 'chunk_overlap=20)', 'texts = splitter.split_documents(documents)', 'text_splitter = NLTKTextSplitter()', 'texts = text_splitter.split_documents(documents)', 'create and save the local database', 'load the language model', \"llm = CTransformers(model='./llama-2-7b-chat.ggmlv3.q8_0.bin',\", \"model_type='llama',\", 'gpu_layers=50,', \"config={'max_new_tokens': 1024, 'temperature': 0.05})\", 'prepare a version of the llm pre-loaded with the local content', 'qa_llm = RetrievalQA.from_chain_type(llm=llm,', \"chain_type='stuff',\", 'retriever=retriever,', 'return_source_documents=True,', \"chain_type_kwargs={'prompt': prompt})\", 'ask the AI chat about information in our local files']}\n"
     ]
    }
   ],
   "source": [
    "for i, v in enumerate(documents):\n",
    "    print(i, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bab03d-feb2-461d-affa-c888b66ff52e",
   "metadata": {},
   "source": [
    "# Hybrid Retrieval\n",
    "\n",
    "Combine a sparse search with a dense search - BM25 + Embeddings\n",
    "Reference Article: https://medium.com/etoai/hybrid-search-combining-bm25-and-semantic-search-for-better-results-with-lan-1358038fe7e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbaded8-da27-44de-9bf1-92cfcee5da39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG Kernel",
   "language": "python",
   "name": "rag-codebase"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
